{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Support Vector Machines\n",
    "\n",
    "Just follow along with the notebook and instructions below. You will analyze the famous iris data set!\n",
    "\n",
    "## The Data\n",
    "(http://en.wikipedia.org/wiki/Iris_flower_data_set). \n",
    "\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by Sir Ronald Fisher in the 1936 as an example of discriminant analysis. \n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor), so 150 total samples. Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three classes in the Iris dataset:\n",
    "\n",
    "    Iris-setosa (n=50)\n",
    "    Iris-versicolor (n=50)\n",
    "    Iris-virginica (n=50)\n",
    "\n",
    "The four features of the Iris dataset:\n",
    "\n",
    "    sepal length in cm\n",
    "    sepal width in cm\n",
    "    petal length in cm\n",
    "    petal width in cm\n",
    "\n",
    "## Get the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "**Split your data into a training set and a testing set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model\n",
    "\n",
    "Now its time to train a Support Vector Machine Classifier. \n",
    "\n",
    "**Call the SVC() model from sklearn and fit the model to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "**Now get predictions from the model and create a confusion matrix and a classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0],\n",
       "       [ 0, 38,  3],\n",
       "       [ 0,  3, 36]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(svm_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        40\n",
      "Iris-versicolor       0.93      0.93      0.93        41\n",
      " Iris-virginica       0.92      0.92      0.92        39\n",
      "\n",
      "       accuracy                           0.95       120\n",
      "      macro avg       0.95      0.95      0.95       120\n",
      "   weighted avg       0.95      0.95      0.95       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! You should have noticed that your model was pretty good! Let's see if we can tune the parameters to try to get even better (unlikely, and you probably would be satisfied with these results in real like because the data set is quite small, but I just want you to practice using GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch Practice\n",
    "\n",
    "**Import GridsearchCV from SciKit Learn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary called param_grid and fill out some parameters for C and gamma.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a GridSearchCV object and fit it to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.875, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=3, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.875, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV] ..... n_neighbors=3, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.875, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=4, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.875, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV] ..... n_neighbors=4, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.833, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV] ...... n_neighbors=5, weights=uniform, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.958, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.833, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=1.000, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV] ..... n_neighbors=5, weights=distance, score=0.958, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'n_neighbors': [3, 4, 5],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now take the best grid model and create some predictions using the test set and create classification reports and confusion matrices for them. Were you able to improve?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  0],\n",
       "       [ 0,  0, 11]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "**Build a decision tree classifier. Repeat the same steps. Which model (SVM or decision tree) is better?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = dtree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  0],\n",
       "       [ 0,  0, 11]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The decision tree model is better as seen with the higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
